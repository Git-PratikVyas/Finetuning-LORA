{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** Pratik Vyas\n",
        "\n",
        "**Classification:** Binary classification ( Cancer , non-Cancer)\n",
        "\n",
        "**Usecase:** Distributed Finetuning LLM 'meta-llama/Llama-3.1-8B-Instruct' with LORA"
      ],
      "metadata": {
        "id": "XQOfEBWaHOnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oli34wRCkbWR"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q -U transformers accelerate\n",
        "!pip3 install -q -U bitsandbytes\n",
        "!pip3 install -q -U wandb\n",
        "# !pip3 install -q  -U trl\n",
        "!pip3 install -q  \"trl == 0.12.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO1RnxRTlfLf"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWcJLMK3kvN4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] =\"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\"\n",
        "os.environ[\"WB_KEY\"] = \"9d7decf681236b200a35c0121bca0fe725be724c\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMUpbmcXlFw_"
      },
      "outputs": [],
      "source": [
        "model_id=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "new_model=\"Llama-3.1-8B-Inst_cancer_classification_finetuned\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,   use_auth_token=os.environ[\"HF_TOKEN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PQxBQ3yl7wq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Activate 4-bit precision base model loading\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\", # Quantization type (fp4 or nf4)\n",
        "    bnb_4bit_compute_dtype=\"float16\",  # Compute dtype for 4-bit base models\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    # Enable CPU offloading for specific layers\n",
        "    llm_int8_enable_fp32_cpu_offload=False, # Activate nested quantization for 4-bit base models (double quantization)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "##load model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",  # Let Transformers automatically decide device placement\n",
        "    use_auth_token=os.environ[\"HF_TOKEN\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNnxjP8IwgFW"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5JNOdUyqGtk"
      },
      "outputs": [],
      "source": [
        "# integrate Weights & Biases (W&B) with training process for tracking, monitoring, and collaboration\n",
        "import os\n",
        "import wandb\n",
        "\n",
        "wandb.login(key=os.environ[\"WB_KEY\"])\n",
        "run = wandb.init(\n",
        "    project=\"cancer_classification\",\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxQkXxoDqsO2"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import (AutoModelForCausalLM,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          TrainingArguments,\n",
        "                          pipeline,\n",
        "                          logging)\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             classification_report,\n",
        "                             confusion_matrix)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, PeftConfig\n",
        "from trl import SFTTrainer\n",
        "from trl import setup_chat_format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgzMmEEHrMXf"
      },
      "source": [
        "# Load, preprocess cancer data from zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9riHoDzGrJo4"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "\n",
        "def load_text_files_from_zip_to_dataframe(zip_path, directory_in_zip, **pandas_kwargs):\n",
        "    \"\"\"\n",
        "    Loads text files from a specific directory inside a ZIP archive into a Pandas DataFrame.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    filenames = []\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            for filename in zip_ref.namelist():\n",
        "                if filename.startswith(directory_in_zip) and filename.endswith('.txt'):  # Only process text files\n",
        "                    try:\n",
        "                        with zip_ref.open(filename) as text_file:\n",
        "                            content = text_file.read().decode('utf-8', errors='ignore').strip() # Read file contents, decode from bytes\n",
        "                            data.append(content)\n",
        "                            # Extract the filename without the directory path and extension\n",
        "                            file_no_path = os.path.basename(filename)\n",
        "                            file_no_ext, _ = os.path.splitext(file_no_path)\n",
        "                            filenames.append(file_no_ext)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error reading file {filename}: {e}\")\n",
        "                        continue # Skip to the next file\n",
        "\n",
        "        if not data:\n",
        "            print(f\"No text files found in directory: {directory_in_zip}\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame({'texts': data, 'filename': filenames})  # Create DataFrame\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: ZIP file not found: {zip_path}\")\n",
        "        return None\n",
        "    except zipfile.BadZipFile as e:\n",
        "        print(f\"Error: Invalid ZIP file: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NLa2r9wrYcf"
      },
      "outputs": [],
      "source": [
        "zip_path=\"Dataset.zip\"\n",
        "cancer_df_row = load_text_files_from_zip_to_dataframe(zip_path, 'Dataset/Cancer')\n",
        "cancer_df_row['labels'] = True\n",
        "\n",
        "non_cancer_df_row = load_text_files_from_zip_to_dataframe(zip_path, 'Dataset/Non-Cancer')\n",
        "non_cancer_df_row['labels'] = False\n",
        "\n",
        "display(cancer_df_row.head())\n",
        "display(non_cancer_df_row.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1XjUmvui6YZ"
      },
      "source": [
        "# concat cancer_df_row, non_cancer_df_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRJ_pSKDi5x8"
      },
      "outputs": [],
      "source": [
        "data_df = pd.concat([cancer_df_row, non_cancer_df_row], ignore_index=True)\n",
        "display(data_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VqfwpqkjQWc"
      },
      "source": [
        "# split cancer data into train,test,val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g-PQ7UdjY0Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_train_test_val(df, train_size=0.6, val_size=0.2, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Splits a DataFrame into train, test, and validation sets with specified ratios.\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "        raise TypeError(\"Input must be a Pandas DataFrame.\")\n",
        "\n",
        "    if sum([train_size, test_size, val_size]) != 1.0:\n",
        "        raise ValueError(\"Train, test, and validation sizes must sum to 1.\")\n",
        "\n",
        "    # First split into training and remaining data\n",
        "    train_df, remaining_df = train_test_split(df, train_size=train_size, random_state=random_state)\n",
        "\n",
        "    # Calculate the proportion for test and validation sets from the remaining data\n",
        "    remaining_proportion = 1 - train_size\n",
        "    test_proportion = test_size / remaining_proportion\n",
        "    val_proportion = val_size / remaining_proportion\n",
        "\n",
        "    # Split the remaining data into test and validation sets\n",
        "    test_df, val_df = train_test_split(remaining_df, test_size=test_proportion, random_state=random_state)\n",
        "\n",
        "\n",
        "    return train_df, test_df, val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLRUNdUcjeSi"
      },
      "outputs": [],
      "source": [
        "train_df, test_df, val_df = split_train_test_val(data_df, train_size=0.6, val_size=0.2, test_size=0.2)\n",
        "\n",
        "\n",
        "## train_df reset index\n",
        "train_df.rename(columns={'filename': 'ID'}, inplace=True) # 1. Rename 'filename' column to 'ID'\n",
        "train_df = train_df.set_index('ID') # 2. Set 'ID' as the index (this will shift current index to the side)\n",
        "train_df = train_df.reset_index() # 3. Reset the index to remove the old index (the original integer index)\n",
        "\n",
        "## test_df reset index\n",
        "test_df.rename(columns={'filename': 'ID'}, inplace=True) # 1. Rename 'filename' column to 'ID'\n",
        "test_df = test_df.set_index('ID') # 2. Set 'ID' as the index (this will shift current index to the side)\n",
        "test_df = test_df.reset_index() # 3. Reset the index to remove the old index (the original integer index)\n",
        "\n",
        "## val_df reset index\n",
        "val_df.rename(columns={'filename': 'ID'}, inplace=True) # 1. Rename 'filename' column to 'ID'\n",
        "val_df = val_df.set_index('ID') # 2. Set 'ID' as the index (this will shift current index to the side)\n",
        "val_df = val_df.reset_index() # 3. Reset the index to remove the old index (the original integer index)\n",
        "\n",
        "print(\"Cancer Train DataFrame:\")\n",
        "display(train_df.head())\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "\n",
        "print(\"\\nCancer Test DataFrame:\")\n",
        "display(test_df.head())\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "print(\"\\nCancer Validation DataFrame:\")\n",
        "display(val_df.head())\n",
        "print(f\"Validation shape: {val_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XejbO4Y338f"
      },
      "source": [
        "preprocess text , add prompt and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjTZUdzmJsZh"
      },
      "outputs": [],
      "source": [
        "# Function to perform the text processing\n",
        "\n",
        "import re\n",
        "def process_text(row,isTestSetOrValSet):\n",
        "  # Compile the regex pattern (case-insensitive)\n",
        "  abstract_pattern = re.compile(r\"^\\s*Abstract:\\s*\", re.IGNORECASE | re.MULTILINE)  # Precompile regex\n",
        "\n",
        "  if not bool(abstract_pattern.search(row['texts'])):\n",
        "    text=\"Missing Abstract\"\n",
        "    return text\n",
        "\n",
        "  # Remove identifiers such as 'ID:', 'Title:', 'Abstract:'\n",
        "  # normalized_text = re.sub(r\"(ID:|Title:|Abstract:)\", \"\", row['texts'], flags=re.IGNORECASE)\n",
        "  normalized_text = re.sub(r\"<(?:ID:\\d+)>|Title:|Abstract:\", \"\", row['texts'], flags=re.IGNORECASE)\n",
        "\n",
        "  # Standardize common abbreviations\n",
        "  normalized_text = re.sub(r\"\\bet al\\.\\b\", \"and others\", normalized_text, flags=re.IGNORECASE)\n",
        "  normalized_text = re.sub(r\"\\bvol\\.\\b\", \"volume\", normalized_text, flags=re.IGNORECASE)\n",
        "\n",
        "  # Remove common punctuation marks, but leave periods at the end of sentences\n",
        "  normalized_text = re.sub(r\"[,;@#$%^&*()]\", \"\", normalized_text)\n",
        "\n",
        "  # Ensure consistent spacing, replaces multiple spaces with single ones, and adds space after periods.\n",
        "  normalized_text = \" \".join(normalized_text.split())\n",
        "  normalized_text = re.sub(r\"\\.(?=[A-Z])\", \". \", normalized_text)\n",
        "\n",
        "  # 2. create prompt ( I am adding this in dataset, alternativly it can be passed as function during training)\n",
        "  prompt=f\"You are a medical text classifier. Your task is to determine if the following text is related to cancer or not.\\\n",
        "          \\nLabel text only with 'True' or 'False'.\\\n",
        "          \\nIf text is related to cancer, Label as 'True' otherwise Label as 'False'.\\\n",
        "          \\nDo not provide any additional explanation.\\\n",
        "          \\n\\nText:\\n\"\n",
        "\n",
        "\n",
        "\n",
        "  text = prompt + normalized_text.strip() + \"\\n\\nLabel: \"\n",
        "\n",
        "\n",
        "\n",
        "  # 3. Append actual label in case train dataset\n",
        "  if not isTestSetOrValSet:\n",
        "    text = text + str(row['labels'])\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3aejUIi2BAr"
      },
      "outputs": [],
      "source": [
        "# Apply the processing function with the param isTestSetOrValSet\n",
        "train_df['text'] = train_df.apply(lambda row: process_text(row, isTestSetOrValSet=False), axis=1)\n",
        "train_df.drop(columns=['texts'], inplace=True) # Drop the original 'texts' column\n",
        "\n",
        "test_df['text'] = test_df.apply(lambda row: process_text(row, isTestSetOrValSet=True), axis=1)\n",
        "test_df.drop(columns=['texts'], inplace=True) # Drop the original 'texts' column\n",
        "\n",
        "val_df['text'] = val_df.apply(lambda row: process_text(row, isTestSetOrValSet=True), axis=1)\n",
        "val_df.drop(columns=['texts'], inplace=True) # Drop the original 'texts' column\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFO287fqPN0Y"
      },
      "source": [
        "Remove missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfZwU0ijL2bg"
      },
      "outputs": [],
      "source": [
        "# Remove rows where 'text' column is \"Missing Abstract\"\n",
        "train_df = train_df[train_df['text'] != \"Missing Abstract\"]\n",
        "test_df = test_df[test_df['text'] != \"Missing Abstract\"]\n",
        "val_df = val_df[val_df['text'] != \"Missing Abstract\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLjrzKHa2WS6"
      },
      "outputs": [],
      "source": [
        "train_df[\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAHGR_nd4CtH"
      },
      "outputs": [],
      "source": [
        "test_df[\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjGXMMO_5oXG"
      },
      "outputs": [],
      "source": [
        "val_df[\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xpEGkzaY9DH"
      },
      "outputs": [],
      "source": [
        "# Using list comprehension to count words in text\n",
        "word_counts_text= [len(Title.split()) for Title in train_df[\"text\"]]\n",
        "# Get the maximum number of words\n",
        "word_counts_text = max(word_counts_text)\n",
        "print(f\"Maximum number of tokens in text: {word_counts_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ6an5iGs_uT"
      },
      "source": [
        "convert into dictionary (expected input for model training )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lmNlQ3QtF9v"
      },
      "outputs": [],
      "source": [
        "##convert into dictionary\n",
        "train_df_dict = train_df.to_dict(orient='list') #Convert df to dictionary\n",
        "test_df_dict = test_df.to_dict(orient='list') #Convert df to dictionary\n",
        "val_df_dict = val_df.to_dict(orient='list') #Convert df to dictionary\n",
        "\n",
        "\n",
        "\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Dataset with values as dictionary of col , val\n",
        "training_dataset = Dataset.from_pandas( pd.DataFrame(train_df_dict))\n",
        "test_dataset = Dataset.from_pandas( pd.DataFrame(test_df_dict))\n",
        "val_dataset = Dataset.from_pandas( pd.DataFrame(val_df_dict))\n",
        "\n",
        "print(training_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1HB69JbydY8"
      },
      "source": [
        "# Model evaluation before fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WMCwY5iztK9G"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, logging\n",
        "\n",
        "\n",
        "def predict(test, model, tokenizer):\n",
        "    y_pred = []\n",
        "    categories = [\"True\", \"False\"]\n",
        "\n",
        "    # Assuming 'test' is a list or iterable that you're looping through\n",
        "    total_iterations = len(test)\n",
        "    update_interval = max(1, total_iterations // 5)  # Update every 20% (minimum 1)\n",
        "\n",
        "    # Suppress Transformers warnings and info messages\n",
        "    logging.set_verbosity_error()  # Suppress warnings and informational messages\n",
        "\n",
        "    with tqdm(total=total_iterations, desc=\"Processing\") as pbar:\n",
        "      for i in (range(len(test))):\n",
        "      # for i in (range(5)):\n",
        "\n",
        "\n",
        "        prompt = test_df.iloc[i][\"text\"]\n",
        "        # print(\"--test promp--\")\n",
        "        # print(prompt)\n",
        "        # print(\"----\")\n",
        "        pipe = pipeline(task=\"text-generation\",\n",
        "                        model=model,\n",
        "                        tokenizer=tokenizer,\n",
        "                        max_new_tokens=3,\n",
        "                        temperature=0.1)\n",
        "\n",
        "        result = pipe(prompt)\n",
        "        answer = result[0]['generated_text'].split(\"Label:\")[-1].strip()\n",
        "        # answer = result[0]['generated_text'].split(\"Answer:\")[-1].strip()\n",
        "\n",
        "        # print(\"--prediction--\")\n",
        "        # print(result[0]['generated_text'])\n",
        "        # print(\"----\")\n",
        "        # Determine the predicted category\n",
        "        for category in categories:\n",
        "            if category.lower() in answer.lower():\n",
        "                y_pred.append(category)\n",
        "                break\n",
        "        else:\n",
        "            y_pred.append(\"none\")\n",
        "            # print(result[0]['generated_text'])\n",
        "\n",
        "          # Update every 20%\n",
        "        if (i + 1) % update_interval == 0 or (i + 1) == total_iterations:\n",
        "            pbar.update(update_interval)  # Increment progress bar\n",
        "\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "y_pred = predict(test_df, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ88Nax7aMTU"
      },
      "outputs": [],
      "source": [
        "# Convert to a Pandas Series (for easy counting)\n",
        "y_pred_series = pd.Series(y_pred)\n",
        "\n",
        "# Count the occurrences of each value\n",
        "value_counts = y_pred_series.value_counts()\n",
        "\n",
        "# Print the counts\n",
        "print(\"Value Counts:\")\n",
        "print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO63N8PfLoaW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (accuracy_score,\n",
        "                             classification_report,\n",
        "                             confusion_matrix)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    labels = [\"True\", \"False\"]\n",
        "    mapping = {'True': 1, 'False': 0}\n",
        "    def map_func(x):\n",
        "        return mapping.get(x, 1)\n",
        "\n",
        "    y_true = np.vectorize(map_func)(y_true)\n",
        "    y_pred = np.vectorize(map_func)(y_pred)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "    print(f'Accuracy: {accuracy:.3f}')\n",
        "\n",
        "    # Generate accuracy report\n",
        "    unique_labels = set(y_true)  # Get unique labels\n",
        "\n",
        "    for label in unique_labels:\n",
        "        label_indices = [i for i in range(len(y_true))\n",
        "                         if y_true[i] == label]\n",
        "        label_y_true = [y_true[i] for i in label_indices]\n",
        "        label_y_pred = [y_pred[i] for i in label_indices]\n",
        "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
        "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
        "\n",
        "    # Generate classification report\n",
        "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
        "    print('\\nClassification Report:')\n",
        "    print(class_report)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
        "    print('\\nConfusion Matrix:')\n",
        "    print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES8lVSLaMYE_"
      },
      "outputs": [],
      "source": [
        "y_true = test_df.loc[:,'labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWDJskM9MgO2"
      },
      "outputs": [],
      "source": [
        "logging.set_verbosity_error()  # Suppress warnings and informational messages\n",
        "evaluate(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_uaWp7DCLsD"
      },
      "source": [
        "# LORA Hyper-Parameter tuning (optional)\n",
        "## ( r, lora_alpha, lora_dropout, target_modules )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_KYYNhADwYH"
      },
      "outputs": [],
      "source": [
        "!pip install -q optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IwWG1gBCKbT"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from datasets import DatasetDict\n",
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    # Clear GPU cache before loading the model for the second time\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    num_epochs = 1  # desired number of epochs\n",
        "    # batch_size = 1  # per_device_train_batch_size\n",
        "\n",
        "\n",
        "    # TRAIN_DATA_RECORD_SIZE = 10  # size of train/val dataset\n",
        "    # VAL_DATA_RECORD_SIZE = 3\n",
        "    # train_dataset = training_dataset.select(range(TRAIN_DATA_RECORD_SIZE))\n",
        "    # validation_dataset = val_dataset.select(range(VAL_DATA_RECORD_SIZE))\n",
        "    train_dataset = training_dataset\n",
        "    validation_dataset = val_dataset\n",
        "\n",
        "\n",
        "\n",
        "    # training_dataset = train_df\n",
        "    # val_dataset = val_df\n",
        "\n",
        "    # Define hyperparameters to tune\n",
        "    lora_combination = trial.suggest_categorical(\"lora_combination\", [ (32, 16), (32,32),(64, 32)])\n",
        "    lora_r, lora_alpha = lora_combination\n",
        "    lora_dropout = trial.suggest_categorical(\n",
        "        \"lora_dropout\", [0.2,0.3, 0.4]\n",
        "    )  # Higher Rates for smaller dataset or when you observe signs of overfitting during training\n",
        "\n",
        "\n",
        "    target_modules = trial.suggest_categorical(\n",
        "        \"target_modules\",\n",
        "        [\n",
        "            [\"q_proj\", \"v_proj\"],\n",
        "            [\"q_proj\", \"k_proj\", \"v_proj\"],\n",
        "            [\n",
        "                \"q_proj\",\n",
        "                \"o_proj\",\n",
        "                \"k_proj\",\n",
        "                \"v_proj\",\n",
        "                \"gate_proj\",\n",
        "                \"up_proj\",\n",
        "                \"down_proj\",\n",
        "            ],\n",
        "        ],\n",
        "    )\n",
        "\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=lora_r,  # hyperparam tuning\n",
        "        lora_alpha=lora_alpha,  # hyperparam tuning\n",
        "        lora_dropout=lora_dropout,  # hyperparam tuning\n",
        "        # target_modules=target_modules, # hyperparam tuning\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    # Define training arguments\n",
        "    training_arguments = transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        per_device_eval_batch_size=1,\n",
        "        gradient_accumulation_steps=3,  # 4\n",
        "        num_train_epochs=1,\n",
        "        warmup_steps=3,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=0.2,\n",
        "        # max_steps=15,\n",
        "        learning_rate=1e-4,\n",
        "        weight_decay=1e-2,  # Add weight decay\n",
        "        fp16=True,\n",
        "        bf16=False,\n",
        "        logging_steps=1,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        report_to=None,  # wandb,tensorboard\n",
        "        label_names=[\"labels\"], ## taget column name\n",
        "\n",
        "    )\n",
        "\n",
        "    # Initialize the Accelerator for distributed processing\n",
        "    accelerator = Accelerator()\n",
        "\n",
        "    # Load model\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\", # Quantization type (fp4 or nf4)\n",
        "        bnb_4bit_compute_dtype=\"float16\",  # Compute dtype for 4-bit base models\n",
        "        bnb_4bit_use_double_quant=False,\n",
        "        # Enable CPU offloading for specific layers\n",
        "        llm_int8_enable_fp32_cpu_offload=False, # Activate nested quantization for 4-bit base models (double quantization)\n",
        "        )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",  # Let Transformers automatically decide device placement\n",
        "        use_auth_token=os.environ[\"HF_TOKEN\"]\n",
        "    )\n",
        "\n",
        "    # Prepare the model, optimizer, and datasets with the Accelerator\n",
        "    model, train_dataset, validation_dataset = accelerator.prepare(\n",
        "        model, train_dataset, validation_dataset\n",
        "    )\n",
        "\n",
        "\n",
        "    # Initialize the Trainer\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Ensure pad token is set\n",
        "    tokenizer.padding_side = \"left\"  # it is a decoder-only model, it is generally recommended to set padding_side to \"left\".\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        processing_class=tokenizer,\n",
        "        # data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False ,  return_tensors=\"pt\"),\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=validation_dataset,\n",
        "        # max_seq_length=1000,  ## max seq length to input/output. It is crucial for GPU memory management.\n",
        "        dataset_text_field=\"text\",\n",
        "        args=training_arguments,\n",
        "        peft_config=lora_config,\n",
        "        formatting_func=lambda example: example['text'],  # preprocessing function before input\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "    # Evaluate the model\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "\n",
        "\n",
        "    # Return the evaluation metric to optimize\n",
        "    return eval_results[\"eval_loss\"]\n",
        "\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters: \", best_params)\n",
        "# Print the best performance metrics\n",
        "best_trial = study.best_trial\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"\\n\\n--->Execution Time:\", (end_time - start_time) / 60, \"minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CnQlBL1M4nf"
      },
      "source": [
        "# Finetune Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd1G2rytM6rK"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# set best LORA parameters\n",
        "# Modlues:\n",
        "# up_proj: Up projection layer, likely part of the modelâ€™s feed-forward network.\n",
        "# q_proj: Query projection layer, used in the attention mechanism.\n",
        "# down_proj: Down projection layer, often used after attention or feed-forward layers.\n",
        "# gate_proj: Gating projection layer, possibly used in gated feed-forward networks.\n",
        "# o_proj: Output projection layer, used in the attention mechanism.\n",
        "# k_proj: Key projection layer, used in the attention mechanism.\n",
        "# v_proj: Value projection layer, used in the attention mechanism.\n",
        "################################################################################\n",
        "################################################################################\n",
        "best_lora_dropout =0\n",
        "best_lora_r = 16\n",
        "best_lora_alpha =8\n",
        "best_target_modules = [\n",
        "    \"q_proj\",\n",
        "    \"k_proj\",\n",
        "    \"v_proj\",\n",
        "\n",
        "    \"o_proj\",\n",
        "    \"gate_proj\",\n",
        "    \"up_proj\",\n",
        "    \"down_proj\",\n",
        "\n",
        "]\n",
        "\n",
        "# Define LoRA configuration with the best hyperparameters\n",
        "lora_config = LoraConfig(\n",
        "    r=best_lora_r,\n",
        "    lora_alpha=best_lora_alpha,\n",
        "    lora_dropout=best_lora_dropout,\n",
        "    target_modules=best_target_modules,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "# Define training arguments\n",
        "training_arguments = transformers.TrainingArguments(\n",
        "  per_device_train_batch_size=1,\n",
        "  per_device_eval_batch_size=1,\n",
        "  gradient_accumulation_steps=3,  # 4\n",
        "  gradient_checkpointing=True,\n",
        "  num_train_epochs=1,\n",
        "  # max_steps=25, #25\n",
        "  warmup_steps=3,\n",
        "  eval_strategy=\"steps\",\n",
        "  eval_steps=0.2,\n",
        "  learning_rate=1e-4,\n",
        "  weight_decay=1e-2,  # Add weight decay\n",
        "  fp16=True,\n",
        "  bf16=False,\n",
        "  logging_steps=1,\n",
        "  output_dir=\"outputs_model_training\",\n",
        "  optim=\"paged_adamw_8bit\",\n",
        "  report_to=\"wandb\",  # wandb,tensorboard\n",
        "  label_names=[\"labels\"], ## taget column name\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfYeJgnTOPKP"
      },
      "source": [
        "Distributed training using Accelerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FPHRh2XOSQt"
      },
      "outputs": [],
      "source": [
        "# from transformers import AdamW\n",
        "from accelerate import Accelerator\n",
        "from torch.optim import AdamW\n",
        "\n",
        "\n",
        "# Initialize the Accelerator\n",
        "accelerator = Accelerator()\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=training_arguments.learning_rate)\n",
        "\n",
        "# Prepare the model, tokenizer, datasets, and optimizer with the Accelerator\n",
        "model, optimizer, training_dataset, val_dataset = accelerator.prepare(\n",
        "    model, optimizer, training_dataset, val_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJE-ihcaPnxA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_prompt(example):\n",
        "    return [example['text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfDBBBZ5Ocuc"
      },
      "outputs": [],
      "source": [
        "from accelerate import DistributedType\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Clear GPU cache before loading the model for the second time\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "SAVE_MODEL = True\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Ensure pad token is set\n",
        "#If you pad on the right and haven't shifted labels appropriately, the model might try to predict padding tokens as the \"next\" word, which is incorrect\n",
        "tokenizer.padding_side = \"left\"  # it is a decoder-only model, it is generally recommended to set padding_side to \"left\".\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    train_dataset=training_dataset.select(range(300)), #<<--- limiting due to time,compute constraint\n",
        "    eval_dataset=val_dataset.select(range(100)),\n",
        "    # max_seq_length=1000,  ## max seq length to input/output. It is crucial for GPU memory management.\n",
        "    dataset_text_field=\"text\",\n",
        "    args=training_arguments,\n",
        "    peft_config=lora_config,\n",
        "    formatting_func=lambda example: example['text'],  # preprocessing function before input\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False ,  return_tensors=\"pt\"),\n",
        "\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "\n",
        "# Train the final model\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "# Save the final model\n",
        "# accelerator.wait_for_everyone() method is used to synchronize all processes in a distributed training setup,ensuring that all processes reach the same point before proceeding.\n",
        "# This is crucial for maintaining consistency and coordination across multiple devices (e.g., multiple GPUs or TPUs) during training.\n",
        "accelerator.wait_for_everyone() # Use the Accelerator to manage the training loop\n",
        "if accelerator.is_local_main_process:\n",
        "    if SAVE_MODEL:\n",
        "        print(f\"saving model {new_model}\")\n",
        "        trainer.model.save_pretrained(new_model)\n",
        "        trainer.tokenizer.save_pretrained(new_model)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"\\n\\n--->Execution Time:\", (end_time - start_time) / 60, \"minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Erm2-NS37H"
      },
      "source": [
        "# Evaluate model after finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN8ZZZLJSCem"
      },
      "outputs": [],
      "source": [
        "y_pred = predict(test_df, model, tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MUyVPMJHKSa"
      },
      "outputs": [],
      "source": [
        "# Convert to a Pandas Series (for easy counting)\n",
        "y_pred_series = pd.Series(y_pred)\n",
        "\n",
        "# Count the occurrences of each value\n",
        "value_counts = y_pred_series.value_counts()\n",
        "\n",
        "# Print the counts\n",
        "print(\"Value Counts:\")\n",
        "print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsR9cSnrX9zn"
      },
      "outputs": [],
      "source": [
        "evaluate(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZiBODIFPRPM"
      },
      "outputs": [],
      "source": [
        "wandb.finish()\n",
        "model.config.use_cache = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3Iwvtk6UDvC"
      },
      "source": [
        "# Merge finetuned LORA with pre-trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5kKRsdLUCii"
      },
      "outputs": [],
      "source": [
        "# Clear GPU cache before loading the model for the second time\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "from peft import LoraConfig, PeftModel\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, new_model)\n",
        "finetuned_model = model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jANUFe6WSEsL"
      },
      "source": [
        "# Push Model to Huggingface hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDa-EVWkSFvo"
      },
      "outputs": [],
      "source": [
        "trainer.model.push_to_hub(new_model, use_temp_dir=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}